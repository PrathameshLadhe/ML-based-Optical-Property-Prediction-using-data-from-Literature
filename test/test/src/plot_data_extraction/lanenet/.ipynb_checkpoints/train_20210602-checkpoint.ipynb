{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel.scatter_gather import gather\n",
    "from src.models.model import LaneNet\n",
    "from src.models.loss import DiscriminativeLoss\n",
    "from src.utils.utils import AverageMeter, adjust_learning_rate\n",
    "from src.utils.metrics import batch_pix_accuracy, batch_intersection_union\n",
    "from src.utils.parallel import DataParallelModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dict2class():\n",
    "    def __init__(self, opt):\n",
    "        for key in opt.keys():\n",
    "            setattr(self, key, opt[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and dataloader\n",
    "class PlotDigitizerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, data_type, mode, transforms):\n",
    "        super(PlotDigitizerDataset, self).__init__()\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.max_num_plots = 20\n",
    "        # load all image files\n",
    "        self.imglist = sorted(glob.glob(os.path.join(root, data_type, mode, \"*.png\")))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imglist)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = self.imglist[idx]\n",
    "        mask_path = img_path.replace(\"leftImg8bit\", \"gtFine\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask_img = np.array(Image.open(mask_path))\n",
    "        w,h = img.size\n",
    "        \n",
    "        # generate binary segmentation image\n",
    "        seg_img = np.zeros_like(mask_img)\n",
    "        seg_img[mask_img>0] = 1\n",
    "        seg_img = np.stack([1-seg_img, seg_img])\n",
    "        \n",
    "        \n",
    "        # number of instances in the image\n",
    "        num_instance = min(len(np.unique(mask_img))-1,self.max_num_plots)\n",
    "        \n",
    "        # generate instance image\n",
    "        ins_img = np.zeros_like(mask_img)\n",
    "        ins_img[mask_img>0] = relabel_sequential(mask_img[mask_img>0])[0]\n",
    "        instance_img = np.zeros((self.max_num_plots, h, w))\n",
    "        for i in range(1, num_instance+1):\n",
    "            instance_img[i-1, ins_img == i] = 1\n",
    "        \n",
    "        sample = {}\n",
    "        sample[\"img\"] = img\n",
    "        target = {}\n",
    "        target[\"num_instance\"] = num_instance\n",
    "        target[\"seg_img\"] = seg_img\n",
    "        target[\"instance_img\"] = instance_img\n",
    "        sample[\"target\"] = target\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(sample)\n",
    "        target = sample[\"target\"]\n",
    "        img = sample[\"img\"]\n",
    "        \n",
    "        return img, target[\"seg_img\"], target[\"instance_img\"], target[\"num_instance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transform\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        img, target = sample['img'], sample['target']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = transforms.ToTensor()(img)\n",
    "        target[\"num_instance\"] = torch.as_tensor(target[\"num_instance\"], \n",
    "                                                 dtype=torch.int64)\n",
    "        target[\"seg_img\"] = torch.as_tensor(target[\"seg_img\"], \n",
    "                                            dtype=torch.int64)\n",
    "        target[\"instance_img\"] = torch.as_tensor(target[\"instance_img\"], \n",
    "                                                 dtype=torch.int64)\n",
    "        return {\"img\": image, \"target\": target}\n",
    "    \n",
    "class Normalize():\n",
    "    def __init__(self):\n",
    "        self.mean = (0.485, 0.456, 0.406)\n",
    "        self.std = (0.229, 0.224, 0.225)\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        img = sample['img']\n",
    "        sample['img'] = transforms.Normalize(self.mean, self.std)(img)\n",
    "        return sample\n",
    "\n",
    "class RandomRescale(object):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        self.size = 512\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        img, target = sample['img'], sample['target']\n",
    "        w,h = img.size\n",
    "        if w>h:\n",
    "            nw = self.size\n",
    "            nh = int(nw/w*h)\n",
    "        else:\n",
    "            nh = self.size\n",
    "            nw = nh/h*w\n",
    "        if self.mode == \"train\":\n",
    "            dw = np.random.randint(self.size-nw+1)\n",
    "            dh = np.random.randint(self.size-nh+1)\n",
    "        else:\n",
    "            dw, dh = 0, 0\n",
    "        seg_img = target[\"seg_img\"]\n",
    "        instance_img = target[\"instance_img\"]\n",
    "        \n",
    "        new_seg_img = cv2.resize(seg_img.transpose(1,2,0), \n",
    "                                 (nw, nh), \n",
    "                                 interpolation = cv2.INTER_NEAREST).transpose(2,0,1)\n",
    "        new_instance_img = cv2.resize(instance_img.transpose(1,2,0), \n",
    "                                     (nw, nh), \n",
    "                                     interpolation = cv2.INTER_NEAREST).transpose(2,0,1)\n",
    "        new_img = img.resize((nw, nh))\n",
    "        \n",
    "        img = Image.new(mode=new_img.mode, size=(self.size, self.size))\n",
    "        img.paste(new_img, (dw, dh))\n",
    "        \n",
    "        seg_img = np.zeros((new_seg_img.shape[0], self.size, self.size))\n",
    "        seg_img[:, dh:dh+nh, dw:dw+nw] = new_seg_img\n",
    "        instance_img = np.zeros((new_instance_img.shape[0], self.size, self.size))\n",
    "        instance_img[:,dh:dh+nh, dw:dw+nw] = new_instance_img\n",
    "        \n",
    "        target[\"seg_img\"] = seg_img\n",
    "        target[\"instance_img\"] = instance_img\n",
    "        return {\"img\": img, \"target\": target} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"seed\": 123,\n",
    "    \"batch_size\": 4,\n",
    "    \"num_workers\": 8,\n",
    "    \"root\": \"/home/weixin/Documents/GitProjects/SpatialEmbeddings/data/tmp/leftImg8bit/\",\n",
    "    \"output_file\": None,\n",
    "    \"cnn_type\": \"unet\",\n",
    "    \"embed_dim\": 4,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"lr_update\": 50,\n",
    "}\n",
    "opt = dict2class(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transform = transforms.Compose([RandomRescale(), \n",
    "                                       ToTensor(), \n",
    "                                       Normalize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"train\"\n",
    "mode = \"simu\"\n",
    "dataset = PlotDigitizerDataset(opt.root, data_type, mode, custom_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=opt.batch_size,\n",
    "                                          num_workers=opt.num_workers,\n",
    "                                          shuffle=shuffle,\n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Building model...')\n",
    "model = LaneNet(cnn_type=opt.cnn_type, embed_dim=opt.embed_dim)\n",
    "model = DataParallelModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_disc = DiscriminativeLoss(delta_var=0.5,\n",
    "                                    delta_dist=1.5,\n",
    "                                    norm=2,\n",
    "                                    usegpu=True)\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=opt.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    criterion_disc.cuda()\n",
    "    criterion_ce.cuda()\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "learning_rate = adjust_learning_rate(opt, optimizer, epoch)\n",
    "logger.info('===> Learning rate: %f: ', learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-92cb7775b2ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcriterion_disc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0mcriterion_ce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-30283d54b296>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt, model, criterion_disc, criterion_ce, optimizer, loader)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    " train(\n",
    "    opt,\n",
    "    model,\n",
    "    criterion_disc,\n",
    "    criterion_ce,\n",
    "    optimizer,\n",
    "    train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt, model, criterion_disc, criterion_ce, optimizer, loader):\n",
    "    \"\"\"\n",
    "    Training the network in one epoch\n",
    "    Args:\n",
    "        opt (Namspace): training options\n",
    "        model (LaneNet): a LaneNet model\n",
    "        criterion_disc: a DiscriminativeLoss criterion\n",
    "        criterion_ce: a CrossEntropyLoss criterion\n",
    "        optimizer: optimizer (SGD, Adam, etc)\n",
    "        loader: data loader\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    pbar = tqdm(loader)\n",
    "    for data in pbar:\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images, bin_labels, ins_labels, n_lanes = data\n",
    "\n",
    "        images = Variable(images)\n",
    "        bin_labels = Variable(bin_labels)\n",
    "        ins_labels = Variable(ins_labels)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            bin_labels = bin_labels.cuda()\n",
    "            ins_labels = ins_labels.cuda()\n",
    "            n_lanes = n_lanes.cuda()\n",
    "\n",
    "\n",
    "        if torch.cuda.device_count() <= 1:\n",
    "            bin_preds, ins_preds, hnet_preds = model(images)\n",
    "        else:\n",
    "            bin_preds, ins_preds, hnet_preds = gather(model(images), 0, dim=0)\n",
    "\n",
    "        _, bin_labels_ce = bin_labels.max(1)\n",
    "        ce_loss = criterion_ce(\n",
    "            bin_preds.permute(0, 2, 3, 1).contiguous().view(-1, 2),\n",
    "            bin_labels_ce.view(-1))\n",
    "\n",
    "        disc_loss = criterion_disc(ins_preds, ins_labels, n_lanes)\n",
    "        loss = ce_loss + disc_loss \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_time.update(time.time() - end)\n",
    "\n",
    "        pbar.set_description(\n",
    "            '>>> Training loss={:.6f}, i/o time={data_time.avg:.3f}s, gpu time={batch_time.avg:.3f}s'.format(\n",
    "                loss.item(),\n",
    "                data_time=data_time,\n",
    "                batch_time=batch_time))\n",
    "        end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/weixin/Documents/GitProjects/SpatialEmbeddings/data/tmp/leftImg8bit/train/\"\n",
    "mode = \"simu\"\n",
    "dataset = PlotDigitizerDataset(root=root, mode=mode, transforms=custom_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 512]),\n",
       " torch.Size([2, 512, 512]),\n",
       " torch.Size([20, 512, 512]),\n",
       " tensor(15))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, seg, ins, num_ins = dataset[0]\n",
    "img.shape, seg.shape, ins.shape, num_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(dataset,\n",
    "                              batch_size=opt.batch_size,\n",
    "                              num_workers=opt.num_workers,\n",
    "                              shuffle=shuffle,\n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dict2class():\n",
    "    def __init__(self, opt):\n",
    "        for key in opt.keys():\n",
    "            setattr(self, key, opt[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = dict2class(opt)\n",
    "opt.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed manually for reproducibility.\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "else:\n",
    "    torch.manual_seed(opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (WARNING)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = np.linspace(4,10,7)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7], dtype=int32),\n",
       " ArrayMap(array([ 4,  5,  6,  7,  8,  9, 10], dtype=int32), array([1, 2, 3, 4, 5, 6, 7], dtype=int32)),\n",
       " ArrayMap(array([1, 2, 3, 4, 5, 6, 7], dtype=int32), array([ 4,  5,  6,  7,  8,  9, 10], dtype=int32)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relabel_sequential(a.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(2, size=10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([a,a]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "         True]),\n",
       " array([False, False, False, False, False, False,  True,  True,  True,\n",
       "        False]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~(a==1), a==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e94a20cf3265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_gather\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_data_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitProjects/lanenet/src/dataloader/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtusimple\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuSimpleDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuSimpleTestDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mculane\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCULaneDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCULaneTestDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbdd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBDDDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBDDTestDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdirloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDirDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitProjects/lanenet/src/dataloader/tusimple.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_binary_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_instance_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.dataloader import get_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (plot_digitizer)",
   "language": "python",
   "name": "plot_digitizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
