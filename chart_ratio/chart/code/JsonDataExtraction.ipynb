{"cells":[{"cell_type":"markdown","metadata":{"id":"DZV-xoOXOL9n"},"source":["## Text, Image and Table extraction from Json files \n","\n","\n","Instructions: \n","<br> <br>\n","To run this code successfully, we will need to download the folders \"data\" and \"images\" respectively from the Onedrive on Teams. \n","- Firstly, ensure that you keep this python notebook in your \"data\" folder. Secondly, \"images\" folder should be in the same directory as that of the \"data\" folder. \n","- The first module returns all the images and tables with their respective captions which can be used to study the key-words\n","- The second module will be used to extract images and table with respect to the keywords and then train our model. "]},{"cell_type":"code","source":["!pip install pillow\n","!pip install tqdm\n","!pip install opencv-python\n","!pip install matplotlib\n","!pip install pandas\n","!pip install textract"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cAWeM-EQOqYt","executionInfo":{"status":"ok","timestamp":1651824909641,"user_tz":-330,"elapsed":39077,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}},"outputId":"7c2a4d74-25b3-4483-e451-63ca2ae538c9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Collecting textract\n","  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n","Collecting extract-msg<=0.29.*\n","  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 4.3 MB/s \n","\u001b[?25hCollecting python-pptx~=0.6.18\n","  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 17.0 MB/s \n","\u001b[?25hCollecting docx2txt~=0.8\n","  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n","Collecting six~=1.12.0\n","  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n","Collecting beautifulsoup4~=4.8.0\n","  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 69.1 MB/s \n","\u001b[?25hCollecting pdfminer.six==20191110\n","  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 54.0 MB/s \n","\u001b[?25hCollecting xlrd~=1.2.0\n","  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n","\u001b[K     |████████████████████████████████| 103 kB 79.3 MB/s \n","\u001b[?25hCollecting argcomplete~=1.10.0\n","  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n","Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n","Collecting SpeechRecognition~=3.8.1\n","  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[K     |████████████████████████████████| 32.8 MB 176 kB/s \n","\u001b[?25hCollecting pycryptodome\n","  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 50.8 MB/s \n","\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n","Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.3.2.post1)\n","Collecting ebcdic>=1.1.1\n","  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 76.5 MB/s \n","\u001b[?25hCollecting tzlocal>=2.1\n","  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n","Collecting olefile>=0.46\n","  Downloading olefile-0.46.zip (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 56.1 MB/s \n","\u001b[?25hCollecting compressed-rtf>=1.0.6\n","  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n","Collecting imapclient==2.1.0\n","  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (4.2.6)\n","Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n","Collecting XlsxWriter>=0.5.7\n","  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n","\u001b[K     |████████████████████████████████| 149 kB 55.7 MB/s \n","\u001b[?25hCollecting pytz-deprecation-shim\n","  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n","Collecting backports.zoneinfo\n","  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n","\u001b[K     |████████████████████████████████| 70 kB 10.5 MB/s \n","\u001b[?25hCollecting tzdata\n","  Downloading tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n","\u001b[K     |████████████████████████████████| 339 kB 77.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile, python-pptx\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=a6371738d582db4aef0bccecfc97af9e4f21ba5a8026e772b6b968e08d59162e\n","  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n","  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6204 sha256=39b3ba50e6b85a8959d5f305151811ac530e0a7ec6eb8e426fc342b0597ac251\n","  Stored in directory: /root/.cache/pip/wheels/bb/33/88/88ceee84d1b74b391c086bc594d3fcf80800decfbd6e1ff565\n","  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=dfe1d059a9a73fe00ff8b7faff4c574f649caac131328ffd73098b3c99f5cb67\n","  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n","  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470951 sha256=b53a555bbda8bca1f06bfa9cb7bc50a0e1e04eaec48b523e61858c2a43deea08\n","  Stored in directory: /root/.cache/pip/wheels/a7/ab/f4/52560d0d4bd4055e9261c6df6e51c7b56c2b23cca3dee811a3\n","Successfully built docx2txt compressed-rtf olefile python-pptx\n","Installing collected packages: tzdata, backports.zoneinfo, six, pytz-deprecation-shim, XlsxWriter, tzlocal, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: tzlocal\n","    Found existing installation: tzlocal 1.5.1\n","    Uninstalling tzlocal-1.5.1:\n","      Successfully uninstalled tzlocal-1.5.1\n","  Attempting uninstall: xlrd\n","    Found existing installation: xlrd 1.1.0\n","    Uninstalling xlrd-1.1.0:\n","      Successfully uninstalled xlrd-1.1.0\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n","google-api-python-client 1.12.11 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n","google-api-core 1.31.5 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed SpeechRecognition-3.8.1 XlsxWriter-3.0.3 argcomplete-1.10.3 backports.zoneinfo-0.2.1 beautifulsoup4-4.8.2 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.14.1 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 textract-1.6.5 tzdata-2022.1 tzlocal-4.2 xlrd-1.2.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["six"]}}},"metadata":{}}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"UraKuq6GOL9x","executionInfo":{"status":"error","timestamp":1651824560421,"user_tz":-330,"elapsed":672,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}},"outputId":"4e97243a-4b3c-4a9e-d895-307886d7e11f"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-71e3147f947a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["#import all the required packages \n","from collections import Counter\n","from pathlib import Path\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import cv2, json, os, re\n","import glob, PyPDF2, shutil, textract\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUEDiMihOL90","executionInfo":{"status":"aborted","timestamp":1651821409529,"user_tz":-330,"elapsed":22,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["data_dir = 'data'\n","img_dir = 'test'"]},{"cell_type":"markdown","metadata":{"id":"1SpPdBVmOL92"},"source":["### Module 1 :  Figures with Captions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60rXnvjQOL93","executionInfo":{"status":"aborted","timestamp":1651821409530,"user_tz":-330,"elapsed":22,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["for path in Path(data_dir).iterdir():\n","    if path.name.endswith('.json'):\n","        with path.open(encoding = \"utf-8\") as json_file:\n","            json_data = json.load(json_file)\n","                \n","            for i in range(len(json_data)):\n","                res = [json_data[i]['renderURL'][6:] , json_data[i]['caption']]\n","                \n","                if res[0] in os.listdir(img_dir):\n","                    img = Image.open(img_dir + '/' + res[0])\n","                    plt.figure(dpi = 200)\n","                    plt.title(res[1])\n","                    plt.imshow(img, aspect='auto')\n","                    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4k9Rqtn8OL95"},"source":["### Module 2 : Image/Table selection by using keywords"]},{"cell_type":"markdown","metadata":{"id":"Hud97zDSOL96"},"source":["### Case 1\n","\n","Any of these keywords ‘Bio-oil’, ‘oil’, ‘light fraction’, ‘heavy fraction’, ‘light oil’, ‘heavy oil’, ‘bio oil’, ‘biooil’, ‘bio-oils’, ‘biomass’, ‘biocrude’, ‘bio-crude’, ‘crude’, ‘product’ accompanied by ‘yield’, ‘carbon’, ‘recovery’, ‘CR’, ’production’, ‘distribution’, ‘product’.\n","\n","Pass case: IF (Keyword set A && Keyword set B) == True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXptN5LjOL98","executionInfo":{"status":"aborted","timestamp":1651821409531,"user_tz":-330,"elapsed":22,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["image_data = []\n","table_data = []\n","\n","keywordsA = [\"bio-oil\", \"oil\", \"lightfraction\", \"heavyfraction\", \"lightoil\", \"heavyoil\", \"biooil\",\n","             \"biomass\", \"biocrude\", \"bio-crude\", \"product\"]\n","keywordsB = [\"yeild\", \"yields\", \"carbon\", \"recovery\", \"CR\", \"production\", \"distribution\", \"product\"]\n","\n","# Make the keywords boundary-words\n","patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n","patternB = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsB]))\n","\n","for path in Path(data_dir).iterdir():\n","    if path.name.endswith('.json'):\n","        with path.open(encoding = \"utf-8\") as json_file:\n","            json_data = json.load(json_file)\n","                \n","            for data in json_data:\n","                if data['figType'] == \"Figure\":\n","                    if bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n","                        image_data.append(data['renderURL'][6:])\n","                        \n","                if data['figType'] == \"Table\":\n","                    if bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n","                        table_data.append(data['renderURL'][6:])\n","                \n","# Remove duplicates from the data\n","image_data = set(image_data)\n","table_data = set(table_data)\n","\n","\n","print(set(image_data))\n","# Copy all the images to Case1/images\n","if not os.path.exists('Case1/images'):\n","    os.makedirs('Case1/images')\n","\n","for image in image_data:\n","    shutil.copyfile(img_dir + '/' + image, 'Case1/images' + '/' + image)\n","    \n","# Copy all the tables to Case1/tables\n","if not os.path.exists('Case1/tables'):\n","    os.makedirs('Case1/tables')\n","    \n","for table in table_data:\n","    shutil.copyfile(img_dir + '/' + table, 'Case1/tables' + '/' + table)"]},{"cell_type":"markdown","metadata":{"id":"3sRUSYraOL9-"},"source":["### Case 2\n","\n","If the keywords ‘yield’, ‘carbon’, ‘recovery’, ‘CR’, ’production’, ‘product’ are present but other keywords such as ‘solid’, ‘gas’, ‘aqueous’, ‘glucose’, ‘gaseous’, ‘solids’ are absent and the word next to bio-oil is not ‘of’\n","\n","Pass case: IF ‘yield’, ‘carbon recovery’, ‘recoveries’ == True && ‘Keyword set A’ == False && wordn+1 == ‘of’ is false"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtvHRTHeOL-A","executionInfo":{"status":"aborted","timestamp":1651821409532,"user_tz":-330,"elapsed":22,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["image_data = []\n","table_data = []\n","\n","keywordsA = [\"solid\", \"gas\", \"aqueous\", \"glucose\", \"gaseous\", \"solids\", \"bio-oil of\"]\n","keywordsB = [\"yeild\", \"yields\", \"carbon\", \"recovery\", \"CR\", \"production\", \"distribution\", \"product\"]\n","\n","# Make the keywords boundary-words\n","patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n","patternB = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsB]))\n","\n","for path in Path(data_dir).iterdir():\n","    if path.name.endswith('.json'):\n","        with path.open(encoding = \"utf-8\") as json_file:\n","            json_data = json.load(json_file)\n","                \n","            for data in json_data:\n","                if data['figType'] == \"Figure\":\n","                    if not bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n","                        image_data.append(data['renderURL'][6:])\n","                        \n","                if data['figType'] == \"Table\":\n","                    if not bool(patternA.findall(data['caption'])) and bool(patternB.findall(data['caption'])):\n","                        table_data.append(data['renderURL'][6:])\n","\n","# Remove duplicates from the data\n","image_data = set(image_data)\n","table_data = set(table_data)\n","\n","# Create directory 'Case2/images' and copy the selected images\n","if not os.path.exists('Case2/images'):\n","    os.makedirs('Case2/images')\n","\n","for image in image_data:\n","    shutil.copyfile(img_dir + '/' + image, 'Case2/images' + '/' + image)\n","\n","# Create directory 'Case2/tables' and copy the selected tables\n","if not os.path.exists('Case2/tables'):\n","    os.makedirs('Case2/tables')\n","    \n","for table in table_data:\n","    shutil.copyfile(img_dir + '/' + table, 'Case2/tables' + '/' + table)"]},{"cell_type":"markdown","metadata":{"id":"eVo6-xNdOL-B"},"source":["### Case 3\n","\n","Test for presence of ‘a)’,’b)’, ‘c)’ before checking for plot check\n","\n","Pass case: if ‘Keyword set A’ == true, don’t do plot check "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4u22_9FOL-C","executionInfo":{"status":"aborted","timestamp":1651821409533,"user_tz":-330,"elapsed":22,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["image_data = []\n","table_data = []\n","total_images = []\n","total_tables = []\n","\n","keywordsA = ['a\\)', 'b\\)', 'c\\)']\n","\n","# Make the keywords boundary-words\n","patternA = re.compile('|'.join([word for word in keywordsA]))\n","\n","for path in Path(data_dir).iterdir():\n","    if path.name.endswith('.json'):\n","        with path.open(encoding = \"utf-8\") as json_file:\n","            json_data = json.load(json_file)\n","                \n","            for data in json_data:\n","                if data['figType'] == \"Figure\":\n","                    if bool(patternA.findall(data['caption'])):\n","                        image_data.append(data['renderURL'][6:])\n","                        \n","                if data['figType'] == \"Table\":\n","                    if bool(patternA.findall(data['caption'])):\n","                        table_data.append(data['renderURL'][6:])\n","\n","# Remove duplicates from the data\n","image_data = set(image_data)\n","table_data = set(table_data)\n","\n","# Create directory 'Case3/images' and copy the selected images\n","if not os.path.exists('Case3/images'):\n","    os.makedirs('Case3/images')\n","\n","for image in image_data:\n","    shutil.copyfile(img_dir + '/' + image, 'Case3/images' + '/' + image)\n","        \n","# Create directory 'Case3/tables' and copy the selected tables\n","if not os.path.exists('Case3/tables'):\n","    os.makedirs('Case3/tables')\n","\n","for table in table_data:\n","    shutil.copyfile(img_dir + '/' + table, 'Case3/tables' + '/' + table)"]},{"cell_type":"markdown","metadata":{"id":"EHoaNPQZOL-D"},"source":["### Case 4\n","\n","‘GC/MS’, ‘‘GC-MS’, ‘GC MS’, ‘GCMS’, ‘ion chromatogram’, ‘gas chromatography’, ‘areas’, ‘chromatogram’, ‘peak’, ‘functional’, ’compounds’, ‘composition’ are present\n","\n","Pass case: IF Keyword set A == True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqCOFGKIOL-I","executionInfo":{"status":"aborted","timestamp":1651821409533,"user_tz":-330,"elapsed":22,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["image_data = []\n","table_data = []\n","\n","keywordsA = [\"GC/MS\", \"GC-MS\", \"GC MS\", \"GCMS\", \"ion chromatogram\", \"gas chromatography\",\n","             \"areas\", \"chromatogram\", \"peak\", \"functional\", \"compounds\", \"composition\"]\n","\n","# Make the keywords boundary-words\n","patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n","\n","for path in Path(data_dir).iterdir():\n","    if path.name.endswith('.json'):\n","        with path.open(encoding = \"utf-8\") as json_file:\n","            json_data = json.load(json_file)\n","                \n","            for data in json_data:\n","                if data['figType'] == \"Figure\":\n","                    if bool(patternA.findall(data['caption'])):\n","                        image_data.append(data['renderURL'][6:])\n","                        \n","                if data['figType'] == \"Table\":\n","                    if bool(patternA.findall(data['caption'])):\n","                        table_data.append(data['renderURL'][6:])\n","\n","# Remove duplicates from the data\n","image_data = set(image_data)\n","table_data = set(table_data)\n","\n","# Create directory 'Case4/images' and copy the selected images\n","if not os.path.exists('Case4/images'):\n","    os.makedirs('Case4/images')\n","\n","for image in image_data:\n","    shutil.copyfile(img_dir + '/' + image, 'Case4/images' + '/' + image)\n","        \n","# Create directory 'Case4/tables' and copy the selected tables\n","if not os.path.exists('Case4/tables'):\n","    os.makedirs('Case4/tables')\n","\n","for table in table_data:\n","    shutil.copyfile(img_dir + '/' + table, 'Case4/tables' + '/' + table)"]},{"cell_type":"markdown","metadata":{"id":"hZrqSYDNOL-K"},"source":["### Case 5\n","\n","‘Biochemical’, ‘proximate’, ‘ultimate’, ‘elemental’ are present\n","\n","Pass case: IF Keyword set A == True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAFuqs4FOL-L","executionInfo":{"status":"aborted","timestamp":1651821409534,"user_tz":-330,"elapsed":22,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["image_data = []\n","table_data = []\n","\n","keywordsA = [\"Biochemical\", \"proximate\", \"ultimate\", \"elemental\"]\n","    \n","# Make the keywords boundary-words\n","patternA = re.compile('|'.join([r'\\b' + word + r'\\b' for word in keywordsA]))\n","\n","for path in Path(data_dir).iterdir():\n","    if path.name.endswith('.json'):\n","        with path.open(encoding = \"utf-8\") as json_file:\n","            json_data = json.load(json_file)\n","                \n","            for data in json_data:\n","                if data['figType'] == \"Figure\":\n","                    if bool(patternA.findall(data['caption'])):\n","                        image_data.append(data['renderURL'][6:])\n","                        \n","                if data['figType'] == \"Table\":\n","                    if bool(patternA.findall(data['caption'])):\n","                        table_data.append(data['renderURL'][6:])\n","\n","# Remove duplicates from the data\n","image_data = set(image_data)\n","table_data = set(table_data)\n","\n","# Create directory 'Case5/images' and copy the selected images\n","if not os.path.exists('Case5/images'):\n","    os.makedirs('Case5/images')\n","\n","for image in image_data:\n","    shutil.copyfile(img_dir + '/' + image, 'Case5/images' + '/' + image)\n","        \n","# filtered is already created; so just create tables directory and copy all the selected tables\n","if not os.path.exists('Case5/tables'):\n","    os.makedirs('Case5/tables')\n","\n","for table in table_data:\n","    shutil.copyfile(img_dir + '/' + table, 'Case5/tables' + '/' + table)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WxW-wp1OL-M","executionInfo":{"status":"aborted","timestamp":1651821409536,"user_tz":-330,"elapsed":23,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":["for image in image_data:\n","    if image in os.listdir(img_dir):\n","        \n","        img = cv2.imread(img_dir + '/' + image)\n","        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        edged = cv2.Canny(gray, 0, 250)\n","        contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        rects = [cv2.boundingRect(cnt) for cnt in contours]\n","        rects = sorted(rects, key=lambda x:x[2] * x[3], reverse=True)\n","        x, y, w, h = rects[0]\n","        \n","        cv2.rectangle(img, (x,y), (x + w, y + h), (0, 255, 0), 2)\n","        plt.figure(dpi = 400)\n","        plt.imshow(img, aspect='auto')\n","        plt.show()\n","\n","        nrows, ncols = 1, 4\n","        figsize = [16, 16]\n","        kernelsize = [3, 5, 7, 9]\n","\n","        fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n","\n","        for i, axi in enumerate(ax.flat):\n","            crop_img = img[y:y + h, x:x + w].copy()\n","            gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n","\n","            # Median filter to remove noise\n","            gray = cv2.medianBlur(gray, kernelsize[i])\n","\n","            edged = cv2.Canny(gray, 0, 250)\n","\n","            contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","            cv2.drawContours(crop_img, contours, -1, (0, 255, 0), 3)\n","            axi.imshow(crop_img)\n","\n","            # get indices of row/column\n","            rowid = i // ncols\n","            colid = i % ncols\n","\n","            # write row/col indices as axes' title for identification\n","            axi.set_title(\"Row:\" + str(rowid) + \", Col:\" + str(colid))\n","\n","        plt.tight_layout(True)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLfNNqjbOL-N","executionInfo":{"status":"aborted","timestamp":1651821409537,"user_tz":-330,"elapsed":23,"user":{"displayName":"Harsh Mishra","userId":"06124179168185730385"}}},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"JsonDataExtraction.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}